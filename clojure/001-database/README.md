# **ClojureとPostgreSQLにおけるロジック分割のプラグマティック・アーキテクトガイド**

### **Part I: 基本原則：分離のためのフレームワーク**

このパートでは、議論全体を支配する高レベルのアーキテクチャ原則を確立します。単純なルールを超え、問題について考えるための堅牢なメンタルモデルを構築します。

#### **1. 陳腐な表現を超えて：関心の分離（SoC）に関する現代的視点**

ソフトウェアアーキテクチャの議論において、「関心の分離（Separation of Concerns, SoC）」は頻繁に引用される原則ですが、その解釈はしばしば「ロジックはアプリケーションに、データはデータベースに」という単純な二元論に陥りがちです。しかし、現代的なシステム設計においては、このような硬直的な見方ではなく、システムを明確に定義された責務を持つ個別の部分に分割するという、より洗練されたアプローチが求められます¹。

この文脈において、データベースは単なる「ダムな（賢くない）」ストレージ層ではなく、それ自体が高度でステートフルなコンポーネントであり、独自の責務を持っています。したがって、本質的な問いは「分離するかどうか」ではなく、「どこに境界線を引くか」です。一般的なアプリケーションアーキテクチャは、プレゼンテーション層（UI、APIエンドポイント）、ビジネスロジック層（中核的な処理ロジック）、データアクセス層（DAL: データベース通信の管理）に分割されます¹。このレポートの目的は、PostgreSQLとClojureという技術スタックにおいて、このデータアクセス層（DAL）の適切な責務と範囲を定義することにあります。このアプローチは、SOLID原則、特に単一責任の原則（SRP: Single Responsibility Principle）と密接に関連しており、各層が「変更されるべき理由を一つだけ持つ」べきであるという考えに基づいています³。

この視点から「SQL対アプリケーションロジック」という従来の対立を再構成することが可能です。生産的な問いは、「データアクセス層の単一責任とは何か？」です。もしDALの責任が、「アプリケーションに対して、最も効率的で、一貫性があり、安全な形でデータを提供すること」であるならば、複雑なデータの整形、フィルタリング、集約といった操作は、明確にその責務の範囲内に含まれます。この解釈により、複雑なSQLは「ビジネスロジックの漏洩」ではなく、「DALがその主要な責務を果たしている状態」として捉え直すことができます。この考え方は、アプリケーションとデータベース間のロジック分割を判断するための強力なヒューリスティック（発見的手法）となります。つまり、問題はアプリケーションとデータベースの間の境界ではなく、異なる種類のロジック間の境界にあるのです⁴。DALの役割は、単にSELECT *を実行することではなく、データベース内のデータにのみ関わるすべての「データ中心のロジック」を処理することです。その結果、アプリケーションに残される「ビジネスロジック」は、このデータと他の関心事（外部API、ユーザーセッション、複数ステップのワークフローなど）を調整する役割を担うことになります。

#### **2. 境界線の設定：データロジックとビジネスロジックの区別**

ロジックを効果的に分割するためには、「データロジック」と「ビジネスロジック」を明確に区別することが不可欠です。この二つの概念は、実装場所を決定する際の重要な指針となります。

**データロジック（SQLに最適）**

データロジックとは、データベース内でデータセットに対して操作を行い、データの整合性を強制し、フィルタリング、集約、結合、そしてある形式から別の形式へのデータ変換を行うロジックを指します。その主要な関心事はデータそのものです⁵。

- **例1：** 地域ごとの総売上を計算する。
- **例2：** ある投稿に対する最新10件のコメントを取得する。
- **例3：** 新規レコードが複雑な複数テーブルにまたがる制約に違反しないことを保証する。

これらの操作は、データが格納されている場所、つまりデータベースで実行するのが最も効率的です。

**ビジネスロジック（Clojureに最適）**

ビジネスロジックとは、プロセスを調整し、外部システムと連携し、揮発性の高いビジネスルールに基づいて変更され、あるいは汎用プログラミング言語の表現力やツール群を必要とするロジックを指します⁴。

- **例1：** 注文がデータベースに挿入された後、Stripe APIを呼び出して決済を処理する。
- **例2：** 新規ユーザー登録時に歓迎メールを送信する。
- **例3：** ユーザーの購入履歴と頻繁に変更されるプロモーションルールに基づいて割引を適用する。

これらのロジックは、SQLの宣言的な性質や手続き型言語（PL/pgSQLなど）では表現が困難、あるいは不可能です⁶。Clojureのような強力なエコシステムを持つ言語が、その実装にはるかに適しています。

この技術的な分類に加えて、考慮すべき重要な非技術的側面が「ロジックの揮発性（変更頻度）」です。データベースのロジック（スキーマ、ストアドプロシージャなど）は、マイグレーションプロセスやDBA（データベース管理者）の関与が必要なため、アプリケーションコードに比べて変更の「摩擦」が大きいと認識されがちです⁴。アプリケーションコードのデプロイは、現代的なCI/CDパイプラインを通じて迅速かつ容易に行えることが多いのに対し、データベースの変更はより慎重な計画とリスク管理を伴います⁵。

したがって、あるロジックがSQLで効率的に実装可能であったとしても、ビジネスチームから毎週のように変更要求が来る可能性が高い場合、その開発・デプロイのオーバーヘッドを考慮すると、データベース層での実装は不適切かもしれません。この「揮発性の軸」は、純粋な技術的判断にプラグマティックなフィルターをかけるための重要な視点です。安定的でデータモデルの中核をなすロジックはデータベースの候補となり、実験的であったり、ビジネスの都合で頻繁に変わるロジックはアプリケーション層が適していると言えるでしょう。

#### **3. スケーラビリティの軸：水平的なアプリケーションスケーリング vs 垂直的なデータベーススケーリング**

アーキテクチャを設計する上で、アプリケーション層とデータベース層のスケーリング方法の根本的な違いを理解することは極めて重要です。

- **アプリケーションサーバー**は通常ステートレスであり、ロードバランサーの背後にインスタンスを追加することで**水平的に**スケールさせることができます。これは一般的に安価で容易なスケーリング方法です⁸。

- **データベースサーバー**はステートフルであり、通常はより強力なハードウェア（CPU、RAM、高速なディスク）を追加することで**垂直的に**スケールさせます。これは高価であり、物理的な限界が存在します⁹。

この違いは、ロジックの配置に関して中心的な緊張関係を生み出します。CPU負荷の高い処理をデータベースからアプリケーション層に移すことは、スケーラビリティの観点からは純粋な勝利に見えるかもしれません。しかし、それは「ネットワークを介して転送する必要のあるデータ量を劇的に増加させない」という条件付きです。

「アプリケーションは水平にスケールするからロジックをアプリ側に移すべきだ」という議論は、危険なほど単純化されすぎています。多くのWebアプリケーションにおける真のボトルネックは、データベースのCPUではなく、巨大でフィルタリングされていないデータセットをデータベースからアプリケーションに移動させる際のI/Oとネットワークレイテンシです。ロジックをアプリケーション側に移すことは、しばしばより多くの元データを取得し、それをアプリケーションのメモリ上でフィルタリングすることを意味します。これは、効率的なセットベースのデータベース操作を、非効率的な命令型のアプリケーション側操作に置き換え、ネットワークトラフィックを増大させる行為です。結果として、システム全体のスケーラビリティを損なうことさえあります。

この考察から導かれるのは、スケーラビリティに関するより洗練された原則です。CPUに負荷をかける**ビジネスロジック**はアプリケーションに移すべきですが、I/Oに負荷をかける**データのフィルタリングと集約**はデータベースに留めるべきです。最終的な目標は、ネットワークを介して転送するデータセットを、必要最小限の、最も精密な形にすることです。例えば、1000万行のテーブルから10行を抽出する「作業」を考えます。この作業をアプリケーションで行う場合、1000万行（あるいはその関連カラム）がネットワークを越える必要があり、これは膨大なI/Oコストを生みます。アプリケーションはその後、非効率的なループ処理でデータをフィルタリングします¹¹。一方、データベースでこの作業を行えば、フィルタリングの重い処理はデータベースが担い、わずか10行だけがネットワークを通過します。データベースはこの種のタスクに高度に最適化されています¹⁰。この原則を誤って適用すると、スケーラビリティを向上させるつもりが、かえって悪化させるという皮肉な結果を招きかねません。

### **Part II: データベースの最大活用：PostgreSQLにロジックを保持すべき場合**

このパートでは、ユーザーが直感的に感じている「SQLでやった方がいい」という考えを裏付け、データベースを積極的に活用するべき場面を具体的に論じます。

#### **4. データ重力の法則：ネットワークI/Oの最小化を最優先指令とする**

パフォーマンスに関する最も重要なヒューリスティックは、「データが置かれている場所で計算を実行し、データ転送を最小限に抑える」というものです。これを「データ重力の法則」と呼びます。

典型的な例は、平均や合計の計算です。100万行のデータをアプリケーションに転送して合計を計算するのは、データベースにSUM()関数を実行させて1行の結果を返させるのに比べて、桁違いに非効率です¹⁰。この原則は、結果セットのサイズを大幅に削減するあらゆる操作に適用されます。具体的には、フィルタリング（WHERE）、集約（GROUP BY）、そして選択的なカラム取得（SELECT *ではなくSELECT col1, col2）などが挙げられます¹⁴。

**ケーススタディ：N+1アンチパターン**

N+1クエリ問題は、データ重力の法則に違反する典型的なアンチパターンです。この問題は、まず1つのクエリでN個のアイテムを取得し、その後、各アイテムの関連データを取得するためにN個の追加クエリを実行することで発生します¹⁶。これにより、ネットワークのラウンドトリップが大量に発生し、アプリケーションのパフォーマンスは著しく低下します。

例えば、ブログの投稿一覧を表示し、各投稿のコメントも表示するケースを考えます。

1. SELECT * FROM posts; （1クエリ、N件の投稿を取得）
2. 各投稿についてループ処理： SELECT * FROM comments WHERE post_id = ?; （Nクエリ）

合計でN+1回のデータベースアクセスが発生します。

この問題の解決策は、必要なデータを最小限のクエリ（通常は1回か2回）でまとめて取得することです。

- **Eager Loading（積極的読み込み）:** JOINを使用して、投稿とコメントを1つのクエリで取得します。
  ```sql
  SELECT posts.*, comments.*
  FROM posts
  LEFT JOIN comments ON posts.id = comments.post_id;
  ```

- **Batching（一括処理）:** IN句を使用して、関連するすべてのコメントを1つの追加クエリで取得します。
  ```sql
  -- 1. 投稿を取得
  SELECT * FROM posts;
  -- 2. 取得した投稿IDのリストを使ってコメントを一括取得
  SELECT * FROM comments WHERE post_id IN (1, 2, 3, ...);
  ```

これらのアプローチは、ネットワークI/Oを劇的に削減し、データ重力の法則に従うことで、アプリケーションのパフォーマンスを根本的に改善します¹⁶。

#### **5. セットベース操作の力 vs 命令型処理**

SQLと一般的なアプリケーション言語の根本的な違いの一つは、その処理モデルにあります。SQLは宣言的で**セットベース**の言語であり、アプリケーション言語は命令的で**反復的**な処理を得意とします。

SQLは、データセット全体を一度に操作するように設計・最適化されています。クエリが発行されると、データベースのクエリオプティマイザが宣言全体を分析し、インデックスの使用や結合アルゴリズムの選択など、最も効率的な実行計画を立案します²⁰。このセットベースのアプローチにより、データベースは内部で高度な最適化を行うことができます。

対照的に、アプリケーションコードはレコードを一つずつループ処理する傾向があります。これはプログラマにとって自然な思考プロセスかもしれませんが、「行単位で考える」アプローチは、N+1問題のような非効率なパターンを生み出す温床となります¹⁰。SQLの「セットで考える」アプローチは、特に大規模なデータセットを扱う場合に、パフォーマンス上の圧倒的な優位性をもたらします。プログラマがセットを反復的に扱おうとする傾向は、パフォーマンスの疫病とも言える不要な負荷やN+1問題を引き起こす可能性があるため、可能な限りセットベースのアプローチを用いるべきです¹²。

#### **6. 複雑さの克服：高度なタスクのための保守可能なSQLの記述**

「長いクエリは保守が難しい」というユーザーの懸念は正当なものです。しかし、現代のSQLは、モジュール性と可読性を促進する強力な機能を提供しており、この問題を克服することができます。

##### **6.1. Common Table Expression (CTE)によるクエリのモジュール化**

Common Table Expression（CTE）は、WITH句を用いて、単一のクエリ内で名前付きの一時的な結果セットを作成する機能です²¹。CTEは、深くネストしたサブクエリが引き起こす可読性の問題を解決するための優れたツールです。複雑なクエリを、一連の論理的で順次的なステップに分解することができます²³。

例えば、以下のようなネストしたサブクエリを持つクエリがあったとします。

```sql
SELECT
  d.department_name,
  e.employee_name
FROM employees e
JOIN (
  SELECT department_id, department_name
  FROM departments
  WHERE location = 'Tokyo'
) d ON e.department_id = d.department_id
WHERE e.salary > (
  SELECT AVG(salary)
  FROM employees
  WHERE department_id = d.department_id
);
```

これをCTEを使って書き直すと、各ステップが明確になります。

```sql
WITH TokyoDepartments AS (
  SELECT department_id, department_name
  FROM departments
  WHERE location = 'Tokyo'
),
DepartmentAvgSalary AS (
  SELECT department_id, AVG(salary) as avg_sal
  FROM employees
  GROUP BY department_id
)
SELECT
  td.department_name,
  e.employee_name
FROM employees e
JOIN TokyoDepartments td ON e.department_id = td.department_id
JOIN DepartmentAvgSalary das ON e.department_id = das.department_id
WHERE e.salary > das.avg_sal;
```

このように、CTEは一度定義すれば同じクエリ内で複数回参照することも可能で、再利用性を高め、冗長性を削減します²⁴。CTEは、複雑なSQLを恐れるのではなく、構造化して管理するための強力な武器となります。

##### **6.2. ビューとマテリアライズドビューによるロジックのカプセル化**

CTEとビューは、共に複雑さを管理する手段ですが、その適用範囲と目的において重要な違いがあります。この違いを理解することは、どちらのツールをいつ使うべきかを判断する上で役立ちます。

CTEは、特定の単一クエリの可読性を向上させるための**戦術的**なツールです。その有効範囲は、定義されたクエリの実行期間内に限定されます²⁷。一度きりの複雑なレポートを作成する場合、一連のCTEを使ってロジックを構造化するのは完璧なアプローチです。

一方、ビュー（View）は、CREATE VIEWによって作成される永続的なデータベースオブジェクトであり、多くの異なるクエリやアプリケーションから利用可能な、再利用可能な抽象化を構築するための**戦略的**なツールです。ビューは、複雑な結合のような基礎となる構造を隠蔽し、アプリケーションに対しては単純なテーブルのように振る舞います²⁸。これにより、スキーマが変更された場合でも、ビューの定義を更新するだけで、アプリケーション側のコード変更を最小限に抑えることができます。

ただし、ビューには注意点もあります。ビューは複雑さを隠蔽するため、パフォーマンスの落とし穴を見えにくくすることがあります。SELECT * FROM complex_viewのような単純なクエリが、内部では巨大な結合処理を実行している可能性があり、意図せずパフォーマンスを劣化させるリスクを伴います³⁰。

**マテリアライズドビュー（Materialized View）は、このパフォーマンス問題を解決するための一つの手段です。通常のビューがクエリのエイリアスであるのに対し、マテリアライズドビューはクエリの結果**を物理的に格納します。これにより、ダッシュボードの表示など、複雑で実行に時間のかかるクエリの読み取り性能を劇的に向上させることができます。その代償として、データはREFRESHコマンドが実行された時点のものであり、リアルタイム性が失われるというトレードオフが存在します³⁰。

結論として、以下のガイドラインが導かれます。

- **CTE:** クエリの**内部**ロジックを構造化するために使用します。
- **ビュー:** データに対する安定的で再利用可能な**インターフェース**を作成するために使用します。
- **マテリアライズドビュー:** 読み取り性能が最優先され、ある程度のデータの古さが許容できる集計やレポートのために使用します。

#### **7. PostgreSQLのパワーハウス：ロジックエンジンとしての高度な機能**

PostgreSQLは単なるデータストアではなく、それ自体が強力なデータ処理エンジンです。その高度な機能を活用することで、複雑なアプリケーションロジックを不要にし、データベース内で効率的に処理を完結させることができます。

##### **7.1. ウィンドウ関数：集約を超えたデータベース内分析**

ウィンドウ関数は、現在の行に関連する行のセットに対して計算を実行しますが、GROUP BY句のように行を一つの結果に集約（折りたたみ）しないという特徴を持ちます³²。これにより、各行の個性を保ちつつ、集計値や順位などの情報を付与することが可能になります。

主なユースケースは以下の通りです。

- **ランキング:** RANK()、DENSE_RANK()、ROW_NUMBER() を用いて、パーティション内での順位を付けます。
- **累積合計:** SUM() OVER (...) を用いて、現在行までの累積値を計算します。
- **先行/後続分析:** LAG()、LEAD() を用いて、前の行や次の行の値にアクセスし、期間比較などを行います。
- **移動平均:** AVG() OVER (...) を用いて、直近N件の平均値を計算します³⁵。

例えば、「各従業員の給与と、その従業員が所属する部署の平均給与を比較する」という課題を考えます。従来のSQLでは自己結合（self-join）が必要で複雑になりがちでしたが、ウィンドウ関数を使えば、以下のようにシンプルかつエレガントに記述できます³⁴。

```sql
SELECT
  employee_name,
  department_name,
  salary,
  AVG(salary) OVER (PARTITION BY department_name) AS avg_department_salary
FROM employees;
```

このクエリは、各従業員の行を維持したまま、所属部署全体の平均給与をavg_department_salary列として追加します。このような処理をアプリケーション側で行う場合、複数回のクエリや複雑なデータ操作が必要となり、非効率です。

##### **7.2. JSONB：半構造化データをソースでクエリ・操作する**

現代のアプリケーションでは、スキーマが固定されていない、あるいはネストした構造を持つデータを扱う場面が増えています。PostgreSQLのjsonb型は、このような半構造化データを効率的に扱うための強力なソリューションです。

json型が入力テキストをそのまま保存するのに対し、jsonb型はデータを分解されたバイナリ形式で保存します。これにより、入力時の変換オーバーヘッドはわずかに増加しますが、処理速度は大幅に向上し、インデックス作成も可能になります。特別な理由がない限り、jsonb型を選択することが推奨されます³⁸。

PostgreSQLはjsonbデータを操作するための豊富な演算子を提供します。

- ->: JSONオブジェクトのフィールドをjsonb型として取得します。
- ->>: JSONオブジェクトのフィールドをtext型として取得します。
- @>: 左辺のjsonb値が右辺のjsonb値を含んでいるか（コンテインメント）をチェックします⁴⁰。

これらの演算子により、WHERE句で直接ネストされたデータにアクセスし、フィルタリングすることが可能です。例えば、可変な属性を持つ製品カタログをjsonbでモデル化することで、複雑で硬直的なEAV（Entity-Attribute-Value）モデルを回避できます⁴¹。

さらに、jsonb列にはGIN（Generalized Inverted Index）インデックスを作成でき、@>演算子を用いたコンテインメントクエリを高速化できます。また、特定のキーを頻繁にクエリする場合は、式インデックスが有効です⁴¹。

```sql
-- 'features'オブジェクトに 'waterproof: true' を含む製品を検索
SELECT name FROM products
WHERE attributes @> '{"features": {"waterproof": true}}';

-- 上記クエリを高速化するGINインデックス
CREATE INDEX idx_products_attributes_gin ON products USING GIN (attributes);
```

##### **7.3. ストアドプロシージャと関数の現代的役割**

ストアドプロシージャ（および関数）の利用については、長年にわたり議論があります⁴。現代的な視点での長所と短所は以下の通りです。

**長所:**

- **トランザクションの原子性:** 複数ステップのデータ操作を単一の原子的なトランザクションにカプセル化できます。
- **ネットワーク効率:** 複雑な書き込み処理におけるネットワークのラウンドトリップを削減します。
- **セキュリティ:** アプリケーションにテーブルへの直接的なSELECT/UPDATE権限を与える代わりに、プロシージャへのEXECUTE権限のみを付与することで、セキュアなAPIを提供できます⁵。

**短所:**

- **テストの困難さ:** 単体テストが難しく、ライブデータベース接続と複雑な状態管理が必要になります。
- **バージョン管理:** Gitでの管理がアプリケーションコードほど容易ではありません。
- **ベンダーロックイン:** PL/pgSQLのような手続き型言語は、他のデータベースへの移植性を著しく損ないます。
- **表現力の限界:** PL/pgSQLは、Clojureのような汎用言語に比べて表現力で劣ります⁴。

**推奨事項:**

PostgreSQLの関数やプロシージャは慎重に使用すべきです。これらが最も適しているのは、データ中心の操作であり、複数ステップにわたるトランザクションの整合性が必要で、かつロジックが安定的である場合です。例えば、単純なCHECK制約では表現できない複雑なデータ検証を挿入前に行う、といったケースが考えられます。一般的なビジネスロジックの実装に用いるのは避けるべきです³¹。

### **Part III: アプリケーションの活用：Clojureバックエンドにロジックを移すべき場合**

データベースの能力を最大限に活用する一方で、アプリケーション層にロジックを配置することが明らかに優れた選択となるシナリオも数多く存在します。このパートでは、そのための強力な論拠を提示します。

#### **8. アプリケーションサイドロジックの利点：柔軟性と開発者体験**

##### **8.1. エコシステムの優位性：優れたツール、テスト、デバッグ**

Clojureのような汎用プログラミング言語は、データベースサイドの開発環境と比較して、はるかにリッチなエコシステムを持っています。REPL（Read-Eval-Print Loop）による対話的な開発、高機能なIDE、強力なデバッガなどは、開発者の生産性を飛躍的に向上させます⁶。

特に重要なのがテストの容易さです。アプリケーション層では、単体テストやモッキングが標準的なプラクティスとして確立されています。Clojureの関数をテストするのは簡単ですが、ストアドプロシージャをテストするには、多くの場合、実際のデータベース接続と、テストごとの複雑なデータのセットアップおよびクリーンアップが必要になります⁴。

バージョン管理も同様です。アプリケーションコードをGitで管理するのは当たり前ですが、ストアドプロシージャやビューといったデータベースオブジェクトのバージョン管理は、より煩雑なプロセスを伴うことがあります⁸。

##### **8.2. 自然なオーケストレーター：複雑な複数ステップ、外部連携ワークフローの処理**

アプリケーションは、単なるデータベースクエリ以上の要素を含むビジネスプロセスを調整（オーケストレーション）するのに理想的な場所です。これらのプロセスはデータ中心ではなく、プロセス中心のロジックです。

- **ユーザー登録フロー:**
  1. データベースにユーザーレコードをINSERTする。
  2. 外部のメール配信サービスAPIを呼び出す。
  3. 分析システムにイベントを送信する。
  4. クライアントに成功レスポンスを返す。

- **注文処理フロー:**
  1. 在庫テーブルをUPDATEする。
  2. 決済ゲートウェイAPIを呼び出す。
  3. 注文レコードをINSERTする。
  4. 配送システムにキューを送信する。

このようなロジックをストアドプロシージャ内で管理しようと試みることは、極めて困難で、システムを脆弱にします⁴。

##### **8.3. データベースを超えた高度なキャッシュ戦略**

マテリアライズドビューはデータベース内での一種のキャッシングを提供しますが、アプリケーション層ではより洗練されたキャッシュ戦略を実装できます。

頻繁にアクセスされるが計算コストが高いデータ（特に、データベースの情報と他のソースからの情報を組み合わせた結果）に対して、アプリケーションはインメモリキャッシュ（ClojureのAtomやcore.cacheライブラリなど）や分散キャッシュ（Redis、Memcachedなど）を導入できます⁹。これにより、リクエストごとにデータベースへアクセスする必要がなくなり、応答性とスループットが大幅に向上します。

##### **8.4. 移植性とデータベース非依存性のための設計**

将来的に複数のデータベースバックエンド（例：PostgreSQL、MySQL、SQL Server）をサポートする必要がある場合、ロジックをアプリケーション層に配置することは必須となります⁴。

ウィンドウ関数、jsonb演算子、PL/pgSQLといったPostgreSQL固有の機能は、他のデータベースには移植できません。データアクセスをアプリケーション層のインターフェースの背後に抽象化することで、データベースごとに異なる実装を提供することが可能になります。この柔軟性は、特にSaaS製品や、顧客の環境に応じてデータベースを選択できる必要がある場合に重要です。

### **Part IV: Clojureの流儀：実践的な実装とイディオム**

このパートでは、これまでの一般原則をユーザーの特定の技術スタックに結びつけ、これらのアイデアをClojureで慣用的に実装する方法を示します。

#### **9. Clojureの世界で「コードとしてのSQL」を受け入れる**

ORM（Object-Relational Mapping）が主流ではないClojureの文化は、SQLを直接的に、しかし洗練された方法で扱うことを奨励します。これは、SQLの力を最大限に引き出しつつ、保守性を維持するための独自のソリューションを生み出しました。

##### **9.1. HugSQL：ClojureとSQLファイルの共生関係**

HugSQLは、ユーザーの「ORMを使わない」という哲学に完全に合致する、Clojureコミュニティで広く受け入れられているライブラリです。HugSQLはSQLを隠蔽するのではなく、整理します⁴⁷。

その中心的なメカニズムはシンプルです。SQLクエリは、特別なヘッダーコメント（-- :name、-- :docなど）を持つプレーンな.sqlファイルに記述されます。HugSQLはこれらのファイルを読み込み、指定された名前に基づいてClojure関数を自動的に生成します⁴⁷。

**主な利点:**

このアプローチにより、CTEやウィンドウ関数を含む複雑なSQLを、Clojureコードから分離したクリーンな状態に保つことができます。.sqlファイルは、SQLに対応したツールによるシンタックスハイライトや静的解析の恩恵を受けることができます。これにより、SQLはClojureコードに埋め込まれた醜い文字列ではなく、ファーストクラスの市民として扱われます⁴⁹。これは、長いクエリの保守性に対するユーザーの懸念に直接応えるものです。

例:

**db/queries.sql:**
```sql
-- :name find-users-by-department :? :*
-- :doc 指定された部署の全ユーザーを取得する
SELECT user_id, user_name, email
FROM users
WHERE department_id = :dept-id
ORDER BY user_name;
```

**my-app/db.clj:**
```clojure
(ns my-app.db
  (:require [hugsql.core :as hugsql]))

(hugsql/def-db-fns "db/queries.sql")

;; これにより (find-users-by-department db-spec {:dept-id 123})
;; という関数が自動的に定義される
```

##### **9.2. 動的構築：HoneySQLのようなクエリビルダーを使用すべき場合**

HugSQLはクエリの構造が静的で、値のみが変化する場合に最適ですが、クエリの構造自体が動的に変わるケースもあります。例えば、オプションの検索フィルター、動的なソート順、ユーザーが選択したカラムなどです。このようなクエリを文字列結合で構築するのは、エラーが発生しやすく、SQLインジェクションの脆弱性を生み出します。

ここで活躍するのがHoneySQLのようなクエリビルダーです。HoneySQLは、SQLクエリをClojureのデータ構造（マップとベクタ）としてプログラム的に構築するアプローチを取ります⁵¹。これにより、安全で合成可能な方法で動的なクエリを生成できます⁴⁹。

```clojure
(require '[honey.sql :as sql]
         '[honey.sql.helpers :as h])

(defn build-user-query [params]
  (let [base-query (-> (h/select :id :name :email)
                       (h/from :users))
        filtered-query (if-let [status (:status params)]
                         (-> base-query
                             (h/where [:= :status status]))
                         base-query)]
    (sql/format filtered-query)))

;; (build-user-query {:status "active"})
;; => ["SELECT id, name, email FROM users WHERE status = ?" "active"]

;; (build-user-query {})
;; => ["SELECT id, name, email FROM users"]
```

HugSQLとHoneySQLは競合するものではなく、補完的なツールです。静的なクエリにはHugSQLを、動的なクエリにはHoneySQLを選択するのが一般的なパターンです⁵²。

##### **9.3. next.jdbcによる接続とトランザクションの管理**

HugSQLやHoneySQLがクエリの**生成**を担うライブラリであるのに対し、next.jdbcはクエリの**実行**を担う、現代的で低レベルなライブラリです⁵³。これはclojure.java.jdbcの後継であり、Clojureコミュニティの標準となっています。

本番環境のアプリケーションでは、リクエストごとに接続を確立・破棄するのではなく、コネクションプールを使用することが極めて重要です。next.jdbcはHikariCPのような高性能なコネクションプールと容易に統合できます⁵³。

また、next.jdbcはリソース管理とトランザクション管理のための慣用的な方法を提供します。

- **with-open:** `(with-open [connection (jdbc/get-connection db-spec)] ...)` のように使用し、ブロックを抜ける際に接続が自動的にクローズされることを保証します⁵³。

- **jdbc/with-transaction:** 複数のデータベース操作を単一の原子的なトランザクション内で実行するために使用します。ブロック内で例外が発生した場合、トランザクションは自動的にロールバックされます⁵⁷。

```clojure
(require '[next.jdbc :as jdbc]
         '[next.jdbc.sql :as sql])

(defn transfer-funds [db-spec from-acct to-acct amount]
  (jdbc/with-transaction [tx db-spec]
    (let [from-balance (:balance (sql/get-by-id tx :accounts from-acct))]
      (if (>= from-balance amount)
        (do
          (sql/update! tx :accounts {:balance (- from-balance amount)} {:id from-acct})
          (sql/update! tx :accounts {:balance [:raw "balance + ?" amount]} {:id to-acct})
          {:success true})
        {:success false :error "Insufficient funds"}))))
```

これらのツールを組み合わせることで、Clojure開発者はSQLの全能力を安全かつ保守性の高い方法で活用することができます。

### **Part V: 決定的要因：証拠に基づくアプローチ**

これまでの議論は原則とヒューリスティックに基づいていましたが、最終的な判断は推測ではなく、計測に基づくべきです。パフォーマンスを理由にロジックを移動させる決断は、必ずデータによって裏付けられる必要があります¹⁰。

#### **10. ヒューリスティックからハードデータへ：パフォーマンスプロファイリングガイド**

##### **10.1. 茶葉を読む：PostgreSQLにおけるEXPLAIN ANALYZEの解釈**

EXPLAIN ANALYZEは、データベースのパフォーマンスを理解するための最も重要な単一のツールです。これは、PostgreSQLが特定のクエリをどのように実行するかの実行計画と、実際の実行時間や行数などの統計情報を提供します。

EXPLAIN ANALYZEの出力を読み解くことで、以下のようなパフォーマンスのボトルネックを特定できます。

- **Sequential Scan:** 大規模なテーブルに対してインデックスが使われず、全件スキャンが発生している。
- **Inefficient Joins:** 不適切な結合アルゴリズム（例：巨大なテーブル間のNested Loop Join）が選択されている。
- **Costly Sorts:** 大量のデータをメモリ外にソートしており、ディスクI/Oが発生している。
- **Incorrect Cardinality Estimates:** オプティマイザの行数見積もりが不正確で、非効率な計画が生成されている。

EXPLAIN ANALYZEの出力を視覚化するツール（例：PEV - Postgres Explain Viewer）を利用すると、複雑な計画の理解が容易になります⁵⁹。pganalyzeのようなツールは、EXPLAIN計画を時系列で収集・分析し、より高度な洞察を提供します⁶⁰。

##### **10.2. clj-async-profilerによるアプリケーションボトルネックの発見**

データベースクエリが最適化されていても、アプリケーション側にボトルネックが存在する可能性があります。clj-async-profilerは、Clojureアプリケーション用の低オーバーヘッドで高精度なプロファイラです⁶²。

このツールは、アプリケーションのCPU時間がどこで消費されているかを視覚化する**フレームグラフ**を生成します。フレームグラフを分析することで、以下のような点を明らかにできます。

- アプリケーションの処理ロジック自体がCPUを大量に消費しているのか？
- それとも、アプリケーションは主にデータベースからのI/O応答を待っているだけなのか？

後者の場合、問題の根本は依然としてデータベースクエリにある可能性が高いことを示唆します。clj-async-profilerは、ボトルネックが本当にアプリケーション側にあるのか、それともデータベース側にあるのかを切り分けるための強力な証拠を提供します⁵⁸。

##### **10.3. 統合ツールによる全体的な可観測性**

最も効果的なパフォーマンスチューニングは、アプリケーションの振る舞いとデータベースのパフォーマンスを相関させて分析することです。pganalyze、New Relic、Datadogといった統合監視ツールは、アプリケーションのトランザクションから発行された特定のSQLクエリを追跡し、両方のパフォーマンスメトリクスを単一のダッシュボードで確認することを可能にします¹⁶。

また、PostgreSQLの拡張機能であるpg_stat_statementsを有効にすると、サーバー上で実行されたクエリの統計情報（実行回数、合計時間、平均時間など）を集約して表示でき、システム全体でどのクエリが最も負荷をかけているかを特定するのに非常に役立ちます⁶¹。

### **Part VI: 統合と推奨事項**

この最終パートでは、これまでの分析を統合し、簡潔で実行可能な推奨事項としてまとめます。

#### **11. ロジック配置のための実践的な意思決定マトリクス**

以下のマトリクスは、本レポートで議論された原則を要約し、一般的な開発タスクにおいてロジックをどこに配置すべきかの迅速な参照ガイドとして機能します。

| **タスク / ロジックパターン**                                           | **デフォルト配置**   | **主要な論理的根拠**               | **推奨PostgreSQLツール/機能**                                   | **推奨Clojureアプローチ**                                            | **避けるべき主要な落とし穴**                                                                              |
| ----------------------------------------------------------------------- | -------------------- | ---------------------------------- | --------------------------------------------------------------- | -------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------- |
| **単純なCRUD** (単一レコードの取得/挿入/更新)                           | アプリケーション     | シンプルさ、保守性                 | 基本的なSELECT/INSERT/UPDATE                                    | next.jdbcヘルパーまたは単純なHugSQL関数                              | 単純なタスクに対する過剰なエンジニアリング。                                                              |
| **データフィルタリングと検索** (巨大テーブルのサブセットを返す)         | **SQL**              | **パフォーマンス（データ重力）**   | WHERE句、適切なインデックス（B-Tree、jsonbにはGIN）、LIKE/ILIKE | パラメータ付きのHugSQL関数。動的フィルタにはHoneySQL。               | 全データを取得してClojureでフィルタリングすること。関連データのN+1問題。                                  |
| **複雑なレポーティングと分析** (ランキング、累積合計、期間比較)         | **SQL**              | **パフォーマンス、表現力**         | **ウィンドウ関数**、CTE、GROUP BY                               | 複雑な分析クエリを呼び出すHugSQL関数。                               | 分析ロジックをClojureで再実装すること。一つのウィンドウクエリの代わりに複数のクエリを使用すること。       |
| **バルクデータ変換** (ルールに基づき数千行を更新)                       | **SQL**              | **パフォーマンス（セットベース）** | 単一のUPDATE... FROM... WHERE文、バルクINSERTコマンド¹⁴         | HugSQLの:command :execute関数。                                      | 全行を取得し、Clojureで変換後、N個のUPDATE文を送信すること。                                              |
| **複数ステップのビジネスプロセス** (決済・メール送信を伴う注文処理など) | **アプリケーション** | **オーケストレーション、外部I/O**  | （任意）原子的なDB部分のためのストアドファンクション。          | next.jdbcと外部APIへの呼び出しを調整するClojure関数。                | データベースから外部サービスを呼び出そうとすること。過度に複雑なトランザクション。                        |
| **データ整合性と検証** (NOT NULLを超える複雑なルール)                   | **SQL**              | **一貫性、セキュリティ**           | CHECK制約、トリガー、ストアドファンクション（慎重に使用）       | 最初の防御としてのアプリケーションレベルの検証（例：clojure.spec）。 | アプリケーションの検証のみに依存すること。アプリをバイパスする他のツールによるデータ変更を許容すること⁵。 |
| **半構造化データの扱い** (製品属性、ユーザー設定など)                   | **SQL**              | **柔軟性、パフォーマンス**         | jsonbデータ型、->>、@>、GINインデックス                         | クエリ内でjsonb演算子を使用するHugSQL。                              | text型を使いClojureでJSONをパースすること。jsonb列にインデックスを作成しないこと。                        |

#### **12. 結論：両利きの開発者になるために**

本レポートで展開した議論の核心は、硬直的なルールに固執するのではなく、状況に応じて最適なツールを選択するというプラグマティックな姿勢です。目指すべきは、「アプリケーション開発者」や「データベース開発者」といった専門領域に閉じこもるのではなく、システム全体を俯瞰し、両方のツールを自在に使いこなす**両利きのアーキテクト**になることです。

現代のPostgreSQLは、受動的なデータ保管庫ではなく、強力なデータ処理エンジンです。その能力を無視することは、一種の技術的負債を抱え込むことに他なりません。一方で、アプリケーション層は、そのリッチなエコシステム、テスト容易性、そして外部システムとの連携能力において、データベースにはない明確な利点を持っています。

Clojureのエコシステム、特にHugSQLに代表される「コードとしてのSQL」という哲学は、この両利きの開発スタイルを実践するための理想的な環境を提供します。SQLの力を最大限に引き出しながらも、その複雑さを管理し、保守性の高いコードベースを維持することを可能にします。

最終的な推奨事項は、原則に導かれ、計測によって検証しながら、アプリケーションとデータベースの双方の境界を越えて思考することです。これにより、真に堅牢で、スケーラブルで、高性能なシステムを構築することができるでしょう。

#### 引用文献

1. Separation of Concerns: A Fundamental Principle in Software Architecture | by Shelvin Datt, 7月 26, 2025にアクセス、 https://medium.com/@shelvindatt02/separation-of-concerns-a-fundamental-principle-in-software-architecture-22dc61f60098

2. Architectural principles - .NET | Microsoft Learn, 7月 26, 2025にアクセス、 https://learn.microsoft.com/en-us/dotnet/architecture/modern-web-apps-azure/architectural-principles

3. SOLID Design Principles Explained: Building Better Software Architecture - DigitalOcean, 7月 26, 2025にアクセス、 https://www.digitalocean.com/community/conceptual-articles/s-o-l-i-d-the-first-five-principles-of-object-oriented-design

4. Business Logic versus Data Logic - Medium, 7月 26, 2025にアクセス、 https://medium.com/@rmhw/business-logic-versus-data-logic-9e4be45d7007

5. Business Logic in Database versus Code? [closed] - Stack Overflow, 7月 26, 2025にアクセス、 https://stackoverflow.com/questions/1473624/business-logic-in-database-versus-code

6. Stored Procedures vs. Application Logic: When to Use Which? | by Rizqi Mulki | Medium, 7月 26, 2025にアクセス、 https://medium.com/@rizqimulkisrc/stored-procedures-vs-application-logic-when-to-use-which-40fa4908e7c8

7. Pros and Cons of holding all the business logic in stored procedures in web application, 7月 26, 2025にアクセス、 https://softwareengineering.stackexchange.com/questions/158534/pros-and-cons-of-holding-all-the-business-logic-in-stored-procedures-in-web-appl

8. Code in database vs. code in application --- brandur.org, 7月 26, 2025にアクセス、 https://brandur.org/fragments/code-database-vs-app

9. Business logic: Database vs code [duplicate] - Software Engineering Stack Exchange, 7月 26, 2025にアクセス、 https://softwareengineering.stackexchange.com/questions/314490/business-logic-database-vs-code

10. What are the pros and cons of performing calculations in sql vs. in your application, 7月 26, 2025にアクセス、 https://stackoverflow.com/questions/7510092/what-are-the-pros-and-cons-of-performing-calculations-in-sql-vs-in-your-applica

11. Which is better? Performing calculations in sql or in your application : r/programming, 7月 26, 2025にアクセス、 https://www.reddit.com/r/programming/comments/1lwwpp/which_is_better_performing_calculations_in_sql_or/

12. How much business logic should the database implement? - Software Engineering Stack Exchange, 7月 26, 2025にアクセス、 https://softwareengineering.stackexchange.com/questions/194446/how-much-business-logic-should-the-database-implement

13. SQL Performance Checklist for Large Datasets - Tinybird, 7月 26, 2025にアクセス、 https://www.tinybird.co/blog-posts/sql-performance-checklist-for-large-datasets-sb

14. SQL Performance Best Practices - CockroachDB, 7月 26, 2025にアクセス、 https://www.cockroachlabs.com/docs/stable/performance-best-practices-overview

15. How to Optimize SQL for Large Data Sets | Built In, 7月 26, 2025にアクセス、 https://builtin.com/articles/optimize-sql-for-large-data-sets

16. How to Efficiently Solve the N+1 Query Problem - TiDB, 7月 26, 2025にアクセス、 https://www.pingcap.com/article/how-to-efficiently-solve-the-n1-query-problem/

17. Understanding the N+1 Problem in REST API Design: Causes, Consequences, and Solutions | by Bhagwan Sahane | Medium, 7月 26, 2025にアクセス、 https://medium.com/@bvsahane89/understanding-the-n-1-problem-in-rest-api-design-causes-consequences-and-solutions-28d9d3d47860

18. The N+1 Query Problem: What Is It And How Do You Solve It? - EVNE Developers, 7月 26, 2025にアクセス、 https://evnedev.com/blog/development/the-n1-query-problem-what-is-it-and-how-do-you-solve-it/

19. Avoiding N+1 Database Queries in ASP.NET: A Practical Guide | PullRequest Blog, 7月 26, 2025にアクセス、 https://www.pullrequest.com/blog/avoiding-n-1-database-queries-in-asp-net-a-practical-guide/

20. What is the best way to manage complex queries in SQL? - Quora, 7月 26, 2025にアクセス、 https://www.quora.com/What-is-the-best-way-to-manage-complex-queries-in-SQL

21. SQL Common Table Expression (CTE) - Syntax, Use Cases, and Examples | Hightouch, 7月 26, 2025にアクセス、 https://hightouch.com/sql-dictionary/sql-common-table-expression-cte

22. CTE in SQL - GeeksforGeeks, 7月 26, 2025にアクセス、 https://www.geeksforgeeks.org/sql/cte-in-sql/

23. When And How To Use CTEs (Common Table Expressions) - Sigma Computing, 7月 26, 2025にアクセス、 https://www.sigmacomputing.com/blog/common-table-expressions

24. Pros and Cons of CTEs and Subqueries in SQL - The Data School, 7月 26, 2025にアクセス、 https://www.thedataschool.co.uk/michael-bellamy/pros